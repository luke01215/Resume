{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sre = pd.read_csv(r\"C:\\Users\\luke0\\Downloads\\diffbot-export.csv\")\n",
    "\n",
    "sre[\"title\"] = [\"Site Reliability Engineer\"] * len (sre)\n",
    "\n",
    "df = pd.concat([sre]).reset_index(drop=True)\n",
    "df = df[~df.text.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yarl import URL\n",
    "\n",
    "def get_page_source(url: str):\n",
    "    return URL(url).host\n",
    "\n",
    "df[\"page_host\"] = df[\"pageUrl\"].apply(get_page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "top_pages = df[\"page_host\"].value_counts()[:20].to_frame()\n",
    "\n",
    "fig = px.histogram(\n",
    "    top_pages,\n",
    "    x=top_pages.index,\n",
    "    y=\"page_host\",\n",
    "    labels={\"sum of page_host\": \"frequency\", \"index\": \"page host\"},\n",
    ").update_xaxes(\n",
    "    categoryorder=\"total descending\",\n",
    ")\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import texthero as hero\n",
    "\n",
    "# Clean text\n",
    "df[\"text\"] = df[\"text\"].pipe(hero.clean)\n",
    "\n",
    "# Turn a list of text into a string\n",
    "text = \" \".join(df[\"text\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def make_wordcloud(new_text):\n",
    "    \"\"\"'function to make wordcloud\"\"\"\n",
    "\n",
    "    wordcloud = WordCloud(\n",
    "        width=800,\n",
    "        height=800,\n",
    "        min_font_size=10,\n",
    "        background_color=\"black\",\n",
    "        colormap=\"Set2\",\n",
    "        collocation_threshold=3,\n",
    "    ).generate(new_text)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8), facecolor=None)\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad=0)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return fig\n",
    "\n",
    "text_cloud = make_wordcloud(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scattertext as st\n",
    "\n",
    "analyze_col = \"requirements\"\n",
    "\n",
    "# Filter out the rows whose requirement is nan\n",
    "filtered_df = df[~df[analyze_col].isna()][[\"title\", analyze_col, \"page_host\"]]\n",
    "\n",
    "# Tokenize text\n",
    "filtered_df[\"parse\"] = filtered_df[analyze_col].apply(st.whitespace_nlp_with_sentences)\n",
    "\n",
    "corpus = (\n",
    "    st.CorpusFromParsedDocuments(filtered_df, category_col=\"title\", parsed_col=\"parse\")\n",
    "    .build()\n",
    "    .get_unigram_corpus()\n",
    "    .compact(st.AssociationCompactor(2000))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "\n",
    "# get DataFrame with terms and their frequency\n",
    "term_freq_df = corpus.get_term_freq_df()\n",
    "\n",
    "# Get scaled F-scores of each term in each category\n",
    "term_freq_df[\"SRE\"] = corpus.get_scaled_f_scores(\"data scientist\")\n",
    "term_freq_df[\"Data Engineer Score\"] = corpus.get_scaled_f_scores(\"data engineer\")\n",
    "\n",
    "# Remove terms that are not nouns\n",
    "def is_noun(word: str):\n",
    "    pos = nltk.pos_tag([word])[0][1]\n",
    "    return pos[:2] == \"NN\"\n",
    "\n",
    "term_freq_df = term_freq_df.loc[map(is_noun, term_freq_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_freq_df.sort_values(by=\"Data Scientist Score\", ascending=False).index[:30]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
